# Point d'entr√©e qui orchestre tout

import time
from scraper import fetch_articles
from storage import save_articles, load_articles

def main():
    seen_links = set(load_articles()["link"])  # Charge les articles d√©j√† connus

    while True:
        print("üîç R√©cup√©ration des articles...")
        articles = fetch_articles(count=20)

        # Filtre uniquement les nouveaux
        new_articles = [a for a in articles if a["link"] not in seen_links]

        if new_articles:
            save_articles(new_articles)
            # Ajoute au set pour √©viter doublons pendant le m√™me run
            seen_links.update(a["link"] for a in new_articles)
        else:
            print("Aucun nouvel article trouv√©.")

        time.sleep(120)  # Attente 2 min avant de relancer

if __name__ == "__main__":
    main()

