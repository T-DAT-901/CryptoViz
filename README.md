# CryptoViz - Terminal de Trading Crypto en Temps R√©el

![Version](https://img.shields.io/badge/version-0.7.4-blue)
![Go](https://img.shields.io/badge/Go-1.23-00ADD8?logo=go&logoColor=white)
![Vue.js](https://img.shields.io/badge/Vue.js-3.3-4FC08D?logo=vue.js&logoColor=white)
![Python](https://img.shields.io/badge/Python-3.11+-3776AB?logo=python&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-Ready-2496ED?logo=docker&logoColor=white)
![TimescaleDB](https://img.shields.io/badge/TimescaleDB-PostgreSQL%2015-FDB515?logo=postgresql&logoColor=white)
![Kafka](https://img.shields.io/badge/Kafka-7.4.0-231F20?logo=apachekafka&logoColor=white)
![License](https://img.shields.io/badge/license-MIT-green)

---

## Table des Mati√®res

- [Pr√©sentation](#pr√©sentation)
- [Captures d'√©cran](#captures-d√©cran)
- [Architecture](#architecture)
- [Points Forts](#points-forts)
- [Stack Technique](#stack-technique)
- [Pr√©requis](#pr√©requis)
- [Installation Rapide](#installation-rapide)
- [Structure du Projet](#structure-du-projet)
- [Services et Ports](#services-et-ports)
- [Pipeline de Donn√©es](#pipeline-de-donn√©es)
- [Optimisations de Performance](#optimisations-de-performance)
- [Data Tiering (Hot/Cold Storage)](#data-tiering-hotcold-storage)
- [Indicateurs Techniques](#indicateurs-techniques)
- [Analyse de Sentiment](#analyse-de-sentiment)
- [API REST](#api-rest)
- [WebSocket Streaming](#websocket-streaming)
- [Commandes Makefile](#commandes-makefile)
- [Monitoring](#monitoring)
- [Configuration](#configuration)
- [Documentation](#documentation)
- [√âquipe et Licence](#√©quipe-et-licence)

---

## Pr√©sentation

**CryptoViz** est une plateforme de visualisation de donn√©es crypto en temps r√©el, con√ßue comme un terminal de trading professionnel. L'architecture microservices permet une scalabilit√© massive et une maintenance optimale.

Le syst√®me ing√®re des donn√©es depuis l'API Binance via WebSocket, les stocke dans TimescaleDB avec un syst√®me de tiering intelligent (hot/cold storage), et les expose via une API REST et WebSocket pour une interface Vue.js interactive.

### Fonctionnalit√©s Cl√©s

- **Streaming temps r√©el** : Throughput optimis√© avec batch commits (30k+/min th√©orique)
- **Historique complet** : Backfill automatique jusqu'√† 365 jours (extensible √† 10+ ans)
- **Indicateurs techniques** : RSI, MACD, Bollinger Bands, Momentum
- **Analyse de sentiment** : Score VADER sur les actualit√©s crypto
- **Data tiering** : 85% d'√©conomies de stockage avec hot/cold storage
- **Cloud-ready** : Architecture pr√™te pour Kubernetes

---

## Captures d'√©cran

### Interface Principale
<!-- SCREENSHOT: crypto-overview -->
*Vue d'ensemble des cryptomonnaies avec prix en temps r√©el*

### Charts de Trading
<!-- SCREENSHOT: trading-chart -->
*Graphiques candlestick interactifs avec s√©lection d'intervalles*

### News Feed
<!-- SCREENSHOT: news-sentiment -->
*Actualit√©s crypto avec score de sentiment (-1 √† +1)*

### Indicateurs Techniques
<!-- SCREENSHOT: indicators-panel -->
*Panneau RSI, MACD, Momentum et Bollinger Bands*

### Monitoring - Grafana
<!-- SCREENSHOT: grafana -->
*Dashboard de m√©triques syst√®me et applicatives*

### Monitoring - Kafka UI
<!-- SCREENSHOT: kafka-ui -->
*Visualisation des topics et messages Kafka*

### Health Checks - Gatus
<!-- SCREENSHOT: gatus -->
*Page de statut des services*

### Object Storage - MinIO
<!-- SCREENSHOT: minio -->
*Console MinIO pour le cold storage S3*

---

## Architecture

```mermaid
flowchart TB
    subgraph Sources["üì° Sources de Donn√©es"]
        Binance[Binance WebSocket]
        RSS[RSS Feeds<br/>CoinDesk, CoinTelegraph]
    end

    subgraph Collectors["üîÑ Collecteurs Python"]
        DC[Data Collector<br/>Trades + OHLCV]
        NS[News Scraper<br/>+ Sentiment VADER]
    end

    subgraph MessageQueue["üì® Apache Kafka"]
        K1[crypto.raw.trades]
        K2[crypto.aggregated.*]
        K4[crypto.news]
    end

    subgraph Backend["‚öôÔ∏è Backend Go"]
        API[REST API<br/>Gin Framework]
        WS[WebSocket Hub<br/>Real-time Streaming]
        Consumers[Kafka Consumers<br/>confluent-kafka-go]
        DB_IO[Database I/O<br/>GORM]
    end

    subgraph Compute["üßÆ Calcul"]
        IS[Indicators Scheduler<br/>Trigger SQL]
        DB_CALC[Calculs en DB<br/>RSI, MACD, Bollinger, Momentum]
    end

    subgraph Storage["üíæ Stockage"]
        TS[(TimescaleDB<br/>Hot Storage)]
        CS[(Cold Storage<br/>Schema PostgreSQL)]
        Redis[(Redis<br/>Cache)]
        MinIO[(MinIO<br/>S3-compatible)]
    end

    subgraph Frontend["üñ•Ô∏è Interface"]
        Vue[Vue.js 3 + TypeScript<br/>Chart.js + D3.js]
    end

    Binance --> DC
    RSS --> NS
    DC --> K1 & K2
    NS --> K4
    K1 & K2 & K4 --> Consumers
    Consumers --> WS
    Consumers --> DB_IO
    DB_IO --> TS
    IS --> DB_CALC
    DB_CALC --> TS
    API --> TS
    API --> Redis
    TS -->|tier_old_*| CS
    CS -.->|export futur| MinIO
    WS <--> Vue
    API <--> Vue
```

### Flux de Donn√©es

- Le **Data Collector** publie vers Kafka (trades et candles agr√©g√©es)
- Le **News Scraper** publie vers Kafka (architecture scalable pour ajouter d'autres sources)
- Le **Backend Go** consomme Kafka, √©crit en DB et streame vers les WebSockets
- Les **indicateurs** sont calcul√©s c√¥t√© base de donn√©es (SQL) sans passer par Kafka

Cette architecture permet :

- **D√©couplage** : Chaque service est ind√©pendant et scalable
- **R√©silience** : Kafka comme buffer si le backend est temporairement down
- **Performance** : Calculs SQL natifs, streaming WebSocket optimis√©
- **Extensibilit√©** : Ajout de nouvelles sources de news sans modification du backend

> **Note** : Une refactorisation future s√©parera la partie REST API de la partie I/O DB dans le backend Go.

---

## Points Forts

### üöÄ Scalabilit√© Massive
- Architecture con√ßue pour **des centaines de cryptomonnaies**
- Historique support√© : **10+ ann√©es de donn√©es**
- Seule limitation : quotas API Binance (tier gratuit = 20 symboles)
- Hypertables partitionn√©es (50 chunks) pour requ√™tes optimis√©es

### ‚ö° Performance
- **30k+ messages/minute** capacit√© th√©orique avec batch commits
- **Latence 3-4ms** du trade √† l'affichage
- **0 consumer lag** gr√¢ce √† confluent-kafka-go + batch commits
- **Requ√™tes hot < 50ms** sur donn√©es r√©centes

### üí∞ Optimisation des Co√ªts
- **85% d'√©conomies** de stockage avec tiering hot/cold
- R√©tention adapt√©e par timeframe (1m: 37j total, 1h: 2+ ans)
- MinIO rempla√ßable par AWS S3 sans changement de code

### üîÑ R√©silience
- **Gap detection** automatique (seuil 2 minutes)
- **Backfill intelligent** qui reprend exactement o√π il s'est arr√™t√©
- **Aucune perte de donn√©es** apr√®s maintenance ou crash

### ‚òÅÔ∏è Cloud-Ready
- Full Docker Compose (17+ services)
- Configuration 100% via variables d'environnement
- Pr√™t pour Kubernetes (manque juste Helm Charts)

---

## Stack Technique

| Couche | Technologie | Version | Description |
|--------|-------------|---------|-------------|
| **Frontend** | Vue.js 3 | 3.3.8 | Interface utilisateur r√©active |
| | TypeScript | 5.2 | Typage statique |
| | Chart.js | 4.5.0 | Graphiques candlestick |
| | D3.js | 7.8.5 | Visualisations avanc√©es |
| | Pinia | 2.3.1 | State management |
| **Backend** | Go | 1.23 | API REST haute performance |
| | Gin | 1.9.1 | Framework HTTP |
| | GORM | 1.25.5 | ORM PostgreSQL |
| | Gorilla WebSocket | 1.5.1 | Streaming temps r√©el |
| | confluent-kafka-go | 2.3.0 | Consumer Kafka |
| **Data Pipeline** | Python | 3.11+ | Collecte et traitement |
| | Binance SDK | - | API WebSocket |
| | VADER Sentiment | - | Analyse de sentiment |
| **Infrastructure** | Apache Kafka | 7.4.0 | Message broker |
| | TimescaleDB | PG15 | Base time-series |
| | Redis | 7 | Cache |
| | MinIO | Latest | Object storage S3 |
| **Monitoring** | Prometheus | Latest | M√©triques |
| | Grafana | Latest | Dashboards |
| | Gatus | Latest | Health checks |

---

## Pr√©requis

- **Docker** 20.10+
- **Docker Compose** 2.0+
- **RAM** : 8GB minimum (16GB recommand√©)
- **Disque** : 20GB minimum
- **Ports disponibles** : 3000, 8080, 7432, 9092, etc.

---

## Installation Rapide

```bash
# 1. Cloner le repository
git clone https://github.com/T-DAT-901/CryptoViz.git
cd CryptoViz

# 2. Configuration initiale
make setup
# √âditer .env si n√©cessaire (cl√©s API Binance optionnelles pour donn√©es publiques)

# 3. Compiler
make build

# 4. D√©marrer tous les services
make start

# 5. V√©rifier l'√©tat
make status
make health

# 6. Acc√©der √† l'interface
# Frontend : http://localhost:3000
# API : http://localhost:8080
# Grafana : http://localhost:3001 (admin/admin)
```

### Commandes de D√©marrage Alternatives

```bash
make start-infra       # Infrastructure seule (DB, Kafka, Redis)
make start-services    # Microservices Python
make start-app         # Backend Go + Frontend Vue
make start-monitoring  # Stack Prometheus/Grafana
```

---

## Structure du Projet

```
CryptoViz/
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ backend-go/           # API REST + WebSocket (Go 1.23)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cmd/server/       # Point d'entr√©e
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ internal/         # Code applicatif (Clean Architecture)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ controllers/  # Handlers HTTP
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ kafka/        # Consumers Kafka
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ middleware/   # CORS, logging
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ websocket/    # Hub + Clients
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ models/           # Entit√©s GORM
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ frontend-vue/         # Interface utilisateur (Vue.js 3)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ src/components/   # Composants r√©utilisables
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ src/services/     # Clients API et WebSocket
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ src/stores/       # State Pinia
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ src/views/        # Pages
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ data-collector/       # Collecte Binance (Python)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ binance_client.py # WebSocket connection
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ aggregator.py     # OHLCV aggregation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ historical_collector.py  # Backfill
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ news-scraper/         # Actualit√©s + Sentiment (Python)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sources/          # Adaptateurs (RSS, Twitter, Reddit...)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ core/             # Kafka producer, sentiment analysis
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ models/           # Article dataclass
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ indicators-scheduler/ # D√©clencheur indicateurs (Python)
‚îÇ       ‚îî‚îÄ‚îÄ scheduler.py      # Trigger des calculs SQL en DB
‚îÇ
‚îú‚îÄ‚îÄ database/
‚îÇ   ‚îú‚îÄ‚îÄ init.sql              # Sch√©ma initial + hypertables
‚îÇ   ‚îú‚îÄ‚îÄ setup-tiering.sql     # Fonctions hot/cold storage
‚îÇ   ‚îú‚îÄ‚îÄ setup-indicators.sql  # Continuous aggregates
‚îÇ   ‚îî‚îÄ‚îÄ 04-backfill-tracking.sql  # Gap detection
‚îÇ
‚îú‚îÄ‚îÄ monitoring/
‚îÇ   ‚îú‚îÄ‚îÄ prometheus/           # Configuration scraping
‚îÇ   ‚îú‚îÄ‚îÄ grafana/              # Dashboards pr√©configur√©s
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dashboards/       # 5 dashboards JSON
‚îÇ   ‚îî‚îÄ‚îÄ gatus/                # Health checks
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ start.sh              # D√©marrage orchestr√©
‚îÇ   ‚îú‚îÄ‚îÄ stop.sh               # Arr√™t propre
‚îÇ   ‚îî‚îÄ‚îÄ demo-tiering.sh       # D√©mo interactive tiering
‚îÇ
‚îú‚îÄ‚îÄ docs/                     # Documentation technique
‚îú‚îÄ‚îÄ docker-compose.yml        # Orchestration 17+ services
‚îú‚îÄ‚îÄ docker-compose.mac.yml    # Override Mac/WSL2
‚îú‚îÄ‚îÄ Makefile                  # 80+ commandes
‚îî‚îÄ‚îÄ .env.example              # Template configuration
```

---

## Services et Ports

| Service | Port | Description |
|---------|------|-------------|
| **frontend-vue** | 3000 | Interface utilisateur Vue.js |
| **backend-go** | 8080 | API REST + WebSocket |
| **timescaledb** | 7432 | Base de donn√©es TimescaleDB |
| **kafka** | 9092 | Message broker |
| **kafka-ui** | 8082 | Interface de gestion Kafka |
| **redis** | 7379 | Cache |
| **minio** | 9000/9001 | API S3 / Console Web |
| **grafana** | 3001 | Dashboards monitoring |
| **prometheus** | 9090 | Collecte m√©triques |
| **gatus** | 8084 | Page de statut |

> **Note** : Les ports non-standards (7432 au lieu de 5432) √©vitent les conflits avec des installations locales.

---

## Pipeline de Donn√©es

```mermaid
sequenceDiagram
    participant B as Binance API
    participant DC as Data Collector
    participant K as Kafka
    participant BG as Backend Go
    participant TS as TimescaleDB
    participant WS as WebSocket
    participant FE as Frontend

    Note over B,FE: Flux d'ingestion temps r√©el

    B->>DC: WebSocket Stream (trades)
    DC->>K: Produce crypto.aggregated.*

    Note over K,FE: Flux de streaming + persistance

    K->>BG: Consume messages
    BG->>TS: INSERT candles
    BG->>WS: Broadcast to subscribers
    WS->>FE: Push temps r√©el

    Note over FE,TS: Flux de requ√™te historique

    FE->>BG: GET /api/v1/crypto/data
    BG->>TS: SELECT FROM all_candles
    TS->>BG: R√©sultats (hot + cold)
    BG->>FE: JSON response
```

### Topics Kafka

| Topic | R√©tention | Description |
|-------|-----------|-------------|
| `crypto.raw.trades` | 48h | Trades individuels |
| `crypto.aggregated.1m` | 30j | Candles 1 minute |
| `crypto.aggregated.5m` | 60j | Candles 5 minutes |
| `crypto.aggregated.15m` | 90j | Candles 15 minutes |
| `crypto.aggregated.1h` | 180j | Candles 1 heure |
| `crypto.aggregated.1d` | 2 ans | Candles journali√®res |
| `crypto.news` | 7j | Articles avec sentiment |

---

## Optimisations de Performance

Le backend Go impl√©mente plusieurs optimisations critiques pour maximiser le throughput de consommation Kafka.

### Batch Commits Kafka

**Probl√®me initial** : Un commit Kafka apr√®s chaque message g√©n√®re une latence de ~10-50ms par message, limitant le throughput √† ~600 messages/minute.

**Solution** : Commits group√©s toutes les 5 secondes via un ticker.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    AVANT (per-message)                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Message 1 ‚Üí Process ‚Üí Commit (10ms)                        ‚îÇ
‚îÇ  Message 2 ‚Üí Process ‚Üí Commit (10ms)                        ‚îÇ
‚îÇ  Message 3 ‚Üí Process ‚Üí Commit (10ms)                        ‚îÇ
‚îÇ  ...                                                         ‚îÇ
‚îÇ  = 600 commits/minute = 600 round-trips broker              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                    APR√àS (batch commit)                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Message 1 ‚Üí Process ‚Üí (pending)                            ‚îÇ
‚îÇ  Message 2 ‚Üí Process ‚Üí (pending)                            ‚îÇ
‚îÇ  ...                                                         ‚îÇ
‚îÇ  [5s ticker] ‚Üí Commit ALL ‚Üí (1 round-trip)                  ‚îÇ
‚îÇ  = 12 commits/minute = 99% moins de round-trips             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Impact** : R√©duction de 99% des round-trips vers le broker Kafka.

### Batch Database Writes

Chaque handler bufferise les messages et les √©crit en batch selon deux crit√®res :

| Handler | Taille Batch | Intervalle Flush | D√©clencheur |
|---------|--------------|------------------|-------------|
| Trades | 500 | 100ms | Premier atteint |
| Candles | 100 | 250ms | Premier atteint |
| Indicators | 50 | 500ms | Premier atteint |
| News | 20 | 1s | Premier atteint |

**Avantages** :
- R√©duction des transactions DB de 90%+
- Utilisation optimale du pool de connexions
- Latence pr√©visible (bounded par l'intervalle)

### Idempotence et S√©curit√©

Toutes les op√©rations restent **idempotentes** gr√¢ce aux clauses `ON CONFLICT` :

```sql
-- Trades : ignore les duplicates
ON CONFLICT (trade_id, exchange, symbol, event_ts) DO NOTHING

-- Candles : merge intelligent des candles ouvertes
ON CONFLICT (window_start, exchange, symbol, timeframe) DO UPDATE SET
    high = GREATEST(candles.high, EXCLUDED.high),
    low = LEAST(candles.low, EXCLUDED.low),
    close = EXCLUDED.close,
    volume = candles.volume + EXCLUDED.volume
WHERE NOT candles.closed

-- Indicators : √©crase avec les valeurs recalcul√©es
ON CONFLICT (time, symbol, timeframe, indicator_type) DO UPDATE SET
    value = EXCLUDED.value
```

**R√©sultat** : Aucune perte de donn√©es en cas de crash, red√©marrage ou retraitement.

### Impact Global

| M√©trique | Avant | Apr√®s | Am√©lioration |
|----------|-------|-------|--------------|
| Kafka round-trips/min | 600+ | 12 | **-99%** |
| DB transactions/min | 600+ | ~50 | **-92%** |
| Throughput potentiel | ~630/min | 30k+/min | **~50x** |
| Latence max (commit) | Variable | 5s | Pr√©visible |

> **Note** : Le throughput r√©el d√©pend du volume de donn√©es entrantes depuis Binance, pas de la capacit√© du backend.

---

## Data Tiering (Hot/Cold Storage)

CryptoViz impl√©mente un syst√®me de **tiering adaptatif** qui optimise les co√ªts de stockage tout en maintenant les performances.

```mermaid
flowchart LR
    subgraph Hot["üî• Hot Storage (SSD)"]
        direction TB
        H1[Donn√©es r√©centes]
        H2[Requ√™tes < 50ms]
        H3[Index optimis√©s]
    end

    subgraph Cold["‚ùÑÔ∏è Cold Storage"]
        direction TB
        C1[Donn√©es historiques]
        C2[85% √©conomies]
        C3[Schema PostgreSQL]
    end

    subgraph Views["üëÅÔ∏è Vues Unifi√©es"]
        direction TB
        V1[all_candles]
        V2[all_indicators]
        V3[all_news]
    end

    Hot -->|"tier_old_*()"| Cold
    Hot --> Views
    Cold --> Views
    Views --> API[Backend API]

    style Hot fill:#ff6b6b,color:#fff
    style Cold fill:#4dabf7,color:#fff
    style Views fill:#51cf66,color:#fff
```

### R√©tention par Timeframe

| Timeframe | Hot Storage | Cold Storage | Total |
|-----------|-------------|--------------|-------|
| **1m** | 7 jours | 30 jours | 37 jours |
| **5m** | 14 jours | 90 jours | 104 jours |
| **15m** | 30 jours | 180 jours | 210 jours |
| **1h** | 90 jours | 730 jours | ~2 ans |
| **1d** | Permanent | - | ‚àû |

### Commandes Tiering

```bash
# Voir les statistiques hot/cold
make tiering-stats

# D√©clencher le tiering manuellement
make tiering

# V√©rifier la configuration
make db-verify-tiering
```

### Architecture Technique

Le tiering utilise **dblink** pour des transactions autonomes, √©vitant les probl√®mes de m√©moire (OOM) lors du d√©placement de grandes quantit√©s de donn√©es :

```sql
-- Chaque batch de 5000 lignes est commit√© ind√©pendamment
SELECT tier_old_candles();  -- D√©place les candles expir√©es
SELECT tier_old_indicators();  -- D√©place les indicateurs expir√©s
SELECT tier_old_news();  -- D√©place les news expir√©es
```

> **Documentation compl√®te** : [docs/COLDSTORAGE.md](docs/COLDSTORAGE.md)

---

## Indicateurs Techniques

| Indicateur | Description | Param√®tres | Formule |
|------------|-------------|------------|---------|
| **RSI** | Relative Strength Index | P√©riode: 14 | RSI = 100 - (100 / (1 + RS)) |
| **MACD** | Moving Average Convergence Divergence | 12, 26, 9 | MACD = EMA(12) - EMA(26) |
| **Bollinger Bands** | Bandes de volatilit√© | P√©riode: 20, √âcart: 2œÉ | Upper/Lower = SMA ¬± 2√óStdDev |
| **Momentum** | Indicateur de momentum | P√©riode: 10 | MOM = Close - Close[n] |

### Calcul et Stockage

Les indicateurs sont **calcul√©s directement en SQL** dans TimescaleDB pour des performances optimales. L'**Indicators Scheduler** (Python) d√©clenche p√©riodiquement les fonctions SQL de calcul.

**Avantages du calcul c√¥t√© DB** :
- Performance native sur les donn√©es time-series
- Pas de transfert de donn√©es entre services
- Utilisation des Continuous Aggregates TimescaleDB
- Pas de surcharge Kafka pour les indicateurs

```bash
# Voir les indicateurs calcul√©s
make db-connect
SELECT * FROM indicators WHERE symbol = 'BTC/USDT' ORDER BY timestamp DESC LIMIT 10;
```

---

## Analyse de Sentiment

Le **News Scraper** int√®gre une analyse de sentiment via VADER (Valence Aware Dictionary and sEntiment Reasoner).

### Fonctionnalit√©s

- **Sources actuelles** : CoinDesk, CoinTelegraph (RSS)
- **Architecture extensible** : Stubs pr√™ts pour Twitter, Reddit et autres sources
- **Score** : -1 (tr√®s n√©gatif) √† +1 (tr√®s positif)
- **D√©tection** : Identification automatique des cryptos mentionn√©es (BTC, ETH, etc.)
- **Scalabilit√© Kafka** : Con√ßu pour g√©rer un grand volume de messages lors de l'ajout de nouvelles sources

### Exemple de R√©sultat

```json
{
  "title": "Bitcoin Surges Past $50,000",
  "sentiment_score": 0.85,
  "symbols": ["BTC", "BTCUSDT"],
  "source": "coindesk",
  "published_at": "2025-01-15T10:30:00Z"
}
```

---

## API REST

Base URL : `http://localhost:8080/api/v1`

| M√©thode | Endpoint | Description |
|---------|----------|-------------|
| GET | `/health` | Health check |
| GET | `/crypto/data?symbol=BTC/USDT&interval=1m` | Donn√©es historiques OHLCV |
| GET | `/crypto/latest?symbol=BTC/USDT` | Dernier prix |
| GET | `/stats?symbol=BTC/USDT` | Statistiques 24h |
| GET | `/indicators/:type?symbol=BTC/USDT` | Indicateur sp√©cifique (rsi, macd, bollinger, momentum) |
| GET | `/indicators?symbol=BTC/USDT` | Tous les indicateurs |
| GET | `/news` | Actualit√©s r√©centes |
| GET | `/news/:symbol` | Actualit√©s par crypto |

### Exemple de Requ√™te

```bash
# R√©cup√©rer les candles 5m de BTC/USDT
curl "http://localhost:8080/api/v1/crypto/data?symbol=BTC/USDT&interval=5m&limit=100"

# R√©cup√©rer le RSI
curl "http://localhost:8080/api/v1/indicators/rsi?symbol=BTC/USDT"
```

> **Documentation compl√®te** : [docs/api.md](docs/api.md)

---

## WebSocket Streaming

Endpoint : `ws://localhost:8080/ws/crypto`

### Messages Support√©s

```json
// Souscrire aux trades BTC
{"action": "subscribe", "type": "trade", "symbol": "BTC/USDT"}

// Souscrire √† toutes les candles 5m
{"action": "subscribe", "type": "candle", "symbol": "*", "timeframe": "5m"}

// Se d√©sabonner
{"action": "unsubscribe", "type": "trade", "symbol": "BTC/USDT"}

// Lister les souscriptions
{"action": "list_subscriptions"}
```

### Formats de R√©ponse

```json
// Trade
{
  "type": "trade",
  "data": {
    "symbol": "BTC/USDT",
    "price": 42150.50,
    "quantity": 0.5,
    "timestamp": "2025-01-15T10:30:00Z"
  }
}

// Candle
{
  "type": "candle",
  "data": {
    "symbol": "BTC/USDT",
    "timeframe": "5m",
    "open": 42100,
    "high": 42200,
    "low": 42050,
    "close": 42150,
    "volume": 125.5
  }
}
```

---

## Commandes Makefile

### Gestion des Services

```bash
make start              # D√©marrer tous les services
make stop               # Arr√™ter proprement
make stop-force         # Arr√™t forc√©
make restart            # Red√©marrer tout
make restart-service SERVICE=backend-go  # Red√©marrer un service
make status             # √âtat des conteneurs
make health             # V√©rifier la sant√©
make logs               # Logs en temps r√©el
make logs-service SERVICE=data-collector  # Logs d'un service
```

### Base de Donn√©es

```bash
make db-connect         # Shell psql
make db-backup          # Sauvegarde
make db-restore BACKUP=file.sql  # Restauration
make db-reset           # Reset complet (‚ö†Ô∏è perte de donn√©es)
make tiering            # Lancer le tiering hot‚Üícold
make tiering-stats      # Distribution hot/cold
```

### Kafka

```bash
make kafka-topics       # Lister les topics
make kafka-console-consumer TOPIC=crypto.raw.trades  # √âcouter un topic
make kafka-create-topic TOPIC=nouveau.topic  # Cr√©er un topic
```

### D√©veloppement

```bash
make dev-backend        # Backend Go en mode dev
make dev-frontend       # Frontend Vue en mode dev
make build              # Construire toutes les images
make build-service SERVICE=backend-go  # Construire un service
make test               # Ex√©cuter les tests
make lint               # V√©rifier le code
make format             # Formater le code
```

### Monitoring

```bash
make monitor            # Afficher toutes les URLs
make grafana-console    # Info connexion Grafana
make prometheus-ui      # Info Prometheus
make minio-console      # Info MinIO
```

---

## Monitoring

### Stack Compl√®te

| Outil | URL | Credentials | Description |
|-------|-----|-------------|-------------|
| **Grafana** | http://localhost:3001 | admin / admin | Dashboards |
| **Prometheus** | http://localhost:9090 | - | M√©triques |
| **Kafka UI** | http://localhost:8082 | - | Topics Kafka |
| **Gatus** | http://localhost:8084 | - | Health checks |
| **MinIO** | http://localhost:9001 | minioadmin / minioadmin | Object storage |

### Dashboards Grafana Pr√©configur√©s

1. **CryptoViz Overview** - M√©triques applicatives
2. **PostgreSQL Database** - M√©triques TimescaleDB
3. **Kafka Exporter** - Lag consumers, throughput
4. **Node Exporter** - M√©triques syst√®me
5. **cAdvisor** - M√©triques conteneurs

### Exporters D√©ploy√©s

- **Node Exporter** (9100) - CPU, RAM, Disk
- **PostgreSQL Exporter** (9187) - Connexions, requ√™tes, locks
- **Redis Exporter** (9121) - Hits/misses, m√©moire
- **Kafka Exporter** (9308) - Lag, messages/sec
- **cAdvisor** (8083) - Conteneurs Docker

---

## Configuration

### Variables d'Environnement Principales

Copier `.env.example` vers `.env` et adapter :

```bash
# API Binance (optionnel pour donn√©es publiques)
BINANCE_API_KEY=
BINANCE_SECRET_KEY=

# Base de donn√©es
TIMESCALE_HOST=timescaledb
TIMESCALE_PORT=5432
TIMESCALE_DB=cryptoviz
TIMESCALE_USER=postgres
TIMESCALE_PASSWORD=password

# Kafka
KAFKA_BROKERS=kafka:29092

# Data Collector
QUOTE_CURRENCIES=USDT,BUSD,FDUSD
MIN_VOLUME=5000000
MAX_SYMBOLS=20
ENABLE_BACKFILL=true
BACKFILL_LOOKBACK_DAYS=365
BACKFILL_TIMEFRAMES=1m,5m,15m,1h,1d

# Frontend (build-time)
VITE_API_URL=http://localhost:8080
VITE_WS_URL=ws://localhost:8080/ws/crypto
VITE_USE_MOCK=false
```

### Configuration Avanc√©e

- **R√©tention tiering** : Configurable par timeframe dans `.env`
- **M√©moire TimescaleDB** : Ajustable dans `docker-compose.yml` (6GB par d√©faut)
- **Partitions Kafka** : 3 par topic par d√©faut

---

## Documentation

| Document | Description |
|----------|-------------|
| [DEV.md](DEV.md) | Guide d√©veloppeur, workflows, troubleshooting |
| [docs/api.md](docs/api.md) | Documentation API REST compl√®te |
| [docs/COLDSTORAGE.md](docs/COLDSTORAGE.md) | Architecture Data Tiering |
| [docs/ARCHITECTURE.md](docs/ARCHITECTURE.md) | Architecture Backend Go |
| [docs/ports-configuration.md](docs/ports-configuration.md) | Configuration des ports |

---

## √âquipe et Licence

### Projet Epitech T-DAT-901

CryptoViz a √©t√© d√©velopp√© dans le cadre du projet **T-DAT-901** √† Epitech.

### Licence

MIT License - voir le fichier [LICENSE](LICENSE) pour plus de d√©tails.

---

<p align="center">
  <b>CryptoViz</b> - Terminal de Trading Crypto en Temps R√©el<br/>
  <sub>Epitech T-DAT-901 | 2025</sub>
</p>
