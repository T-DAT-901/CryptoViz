# CryptoViz - Terminal de Trading Crypto en Temps RÃ©el

![Version](https://img.shields.io/badge/version-0.7.4-blue)
![Go](https://img.shields.io/badge/Go-1.23-00ADD8?logo=go&logoColor=white)
![Vue.js](https://img.shields.io/badge/Vue.js-3.3-4FC08D?logo=vue.js&logoColor=white)
![Python](https://img.shields.io/badge/Python-3.11+-3776AB?logo=python&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-Ready-2496ED?logo=docker&logoColor=white)
![TimescaleDB](https://img.shields.io/badge/TimescaleDB-PostgreSQL%2015-FDB515?logo=postgresql&logoColor=white)
![Kafka](https://img.shields.io/badge/Kafka-7.4.0-231F20?logo=apachekafka&logoColor=white)
![License](https://img.shields.io/badge/license-MIT-green)

---

## Table des MatiÃ¨res

- [PrÃ©sentation](#prÃ©sentation)
- [Captures d'Ã©cran](#captures-dÃ©cran)
- [Architecture](#architecture)
- [Points Forts](#points-forts)
- [Stack Technique](#stack-technique)
- [PrÃ©requis](#prÃ©requis)
- [Installation Rapide](#installation-rapide)
- [Structure du Projet](#structure-du-projet)
- [Services et Ports](#services-et-ports)
- [Pipeline de DonnÃ©es](#pipeline-de-donnÃ©es)
- [Optimisations de Performance](#optimisations-de-performance)
- [Data Tiering (Hot/Cold Storage)](#data-tiering-hotcold-storage)
- [Indicateurs Techniques](#indicateurs-techniques)
- [Analyse de Sentiment](#analyse-de-sentiment)
- [API REST](#api-rest)
- [WebSocket Streaming](#websocket-streaming)
- [Commandes Makefile](#commandes-makefile)
- [Monitoring](#monitoring)
- [Configuration](#configuration)
- [Ã‰volutions Potentielles](#Ã©volutions-potentielles)
- [Documentation](#documentation)
- [Ã‰quipe et Licence](#Ã©quipe-et-licence)

---

## PrÃ©sentation

**CryptoViz** est une plateforme de visualisation de donnÃ©es crypto en temps rÃ©el, conÃ§ue comme un terminal de trading professionnel. L'architecture microservices permet une scalabilitÃ© massive et une maintenance optimale.

Le systÃ¨me ingÃ¨re des donnÃ©es depuis l'API Binance via WebSocket, les stocke dans TimescaleDB avec un systÃ¨me de tiering intelligent (hot/cold storage), et les expose via une API REST et WebSocket pour une interface Vue.js interactive.

### FonctionnalitÃ©s ClÃ©s

- **Streaming temps rÃ©el** : Throughput optimisÃ© avec batch commits (30k+/min thÃ©orique)
- **Historique complet** : Backfill automatique jusqu'Ã  365 jours (extensible Ã  10+ ans)
- **Indicateurs techniques** : RSI, MACD, Bollinger Bands, Momentum
- **Analyse de sentiment** : Score VADER sur les actualitÃ©s crypto
- **Data tiering** : 85% d'Ã©conomies de stockage avec hot/cold storage
- **Cloud-ready** : Architecture prÃªte pour Kubernetes

---

## Captures d'Ã©cran

### Interface Principale
<!-- SCREENSHOT: crypto-overview -->
*Vue d'ensemble des cryptomonnaies avec prix en temps rÃ©el*

### Charts de Trading
<!-- SCREENSHOT: trading-chart -->
*Graphiques candlestick interactifs avec sÃ©lection d'intervalles*

### News Feed
<!-- SCREENSHOT: news-sentiment -->
*ActualitÃ©s crypto avec score de sentiment (-1 Ã  +1)*

### Indicateurs Techniques
<!-- SCREENSHOT: indicators-panel -->
*Panneau RSI, MACD, Momentum et Bollinger Bands*

### Monitoring - Grafana
<!-- SCREENSHOT: grafana -->
*Dashboard de mÃ©triques systÃ¨me et applicatives*

### Monitoring - Kafka UI
<!-- SCREENSHOT: kafka-ui -->
*Visualisation des topics et messages Kafka*

### Health Checks - Gatus
<!-- SCREENSHOT: gatus -->
*Page de statut des services*

### Object Storage - MinIO
<!-- SCREENSHOT: minio -->
*Console MinIO pour le cold storage S3*

---

## Architecture

```mermaid
flowchart TB
    subgraph Sources["ğŸ“¡ Sources de DonnÃ©es"]
        Binance[Binance WebSocket]
        RSS[RSS Feeds<br/>CoinDesk, CoinTelegraph]
    end

    subgraph Collectors["ğŸ”„ Collecteurs Python"]
        DC[Data Collector<br/>Trades + OHLCV]
        NS[News Scraper<br/>+ Sentiment VADER]
    end

    subgraph MessageQueue["ğŸ“¨ Apache Kafka"]
        K1[crypto.raw.trades]
        K2[crypto.aggregated.*]
        K4[crypto.news]
    end

    subgraph Backend["âš™ï¸ Backend Go"]
        API[REST API<br/>Gin Framework]
        WS[WebSocket Hub<br/>Real-time Streaming]
        Consumers[Kafka Consumers<br/>confluent-kafka-go]
        DB_IO[Database I/O<br/>GORM]
    end

    subgraph Compute["ğŸ§® Calcul"]
        IS[Indicators Scheduler<br/>Trigger SQL]
        DB_CALC[Calculs en DB<br/>RSI, MACD, Bollinger, Momentum]
    end

    subgraph Storage["ğŸ’¾ Stockage"]
        TS[(TimescaleDB<br/>Hot Storage)]
        CS[(Cold Storage<br/>Schema PostgreSQL)]
        Redis[(Redis<br/>Cache)]
        MinIO[(MinIO<br/>S3-compatible)]
    end

    subgraph Frontend["ğŸ–¥ï¸ Interface"]
        Vue[Vue.js 3 + TypeScript<br/>Chart.js + D3.js]
    end

    Binance --> DC
    RSS --> NS
    DC --> K1 & K2
    NS --> K4
    K1 & K2 & K4 --> Consumers
    Consumers --> WS
    Consumers --> DB_IO
    DB_IO --> TS
    IS --> DB_CALC
    DB_CALC --> TS
    API --> TS
    API --> Redis
    TS -->|tier_old_*| CS
    CS -.->|export futur| MinIO
    WS <--> Vue
    API <--> Vue
```

### Flux de DonnÃ©es

- Le **Data Collector** publie vers Kafka (trades et candles agrÃ©gÃ©es)
- Le **News Scraper** publie vers Kafka (architecture scalable pour ajouter d'autres sources)
- Le **Backend Go** consomme Kafka, Ã©crit en DB et streame vers les WebSockets
- Les **indicateurs** sont calculÃ©s cÃ´tÃ© base de donnÃ©es (SQL) sans passer par Kafka

Cette architecture permet :

- **DÃ©couplage** : Chaque service est indÃ©pendant et scalable
- **RÃ©silience** : Kafka comme buffer si le backend est temporairement down
- **Performance** : Calculs SQL natifs, streaming WebSocket optimisÃ©
- **ExtensibilitÃ©** : Ajout de nouvelles sources de news sans modification du backend

> **Note** : Une refactorisation future sÃ©parera la partie REST API de la partie I/O DB dans le backend Go.

---

## Points Forts

### ğŸš€ ScalabilitÃ© Massive
- Architecture conÃ§ue pour **des centaines de cryptomonnaies**
- Historique supportÃ© : **10+ annÃ©es de donnÃ©es**
- Seule limitation : quotas API Binance (tier gratuit = 6000 messages/seconde)
- Hypertables partitionnÃ©es (50 chunks) pour requÃªtes optimisÃ©es

### âš¡ Performance
- **100k+ messages/minute** capacitÃ© de consommation des messages kafka
- **Latence 3-4ms** du trade Ã  l'affichage
- **0 consumer lag** grÃ¢ce Ã  confluent-kafka-go + batch commits
- **RequÃªtes hot < 50ms** sur donnÃ©es rÃ©centes

### ğŸ’° Optimisation des CoÃ»ts
- **85% d'Ã©conomies** de stockage avec tiering hot/cold
- RÃ©tention adaptÃ©e par timeframe (1m: 37j total, 1h: 2+ ans)
- MinIO remplaÃ§able par AWS S3 sans changement de code

### ğŸ”„ RÃ©silience
- **Gap detection** automatique (seuil 2 minutes)
- **Backfill intelligent** qui reprend exactement oÃ¹ il s'est arrÃªtÃ©
- **Aucune perte de donnÃ©es** aprÃ¨s maintenance ou crash

### â˜ï¸ Cloud-Ready
- Full Docker Compose (17+ services)
- Configuration 100% via variables d'environnement
- PrÃªt pour Kubernetes (manque juste Helm Charts)

---

## Stack Technique

| Couche | Technologie | Version | Description |
|--------|-------------|---------|-------------|
| **Frontend** | Vue.js 3 | 3.3.8 | Interface utilisateur rÃ©active |
| | TypeScript | 5.2 | Typage statique |
| | Chart.js | 4.5.0 | Graphiques candlestick |
| | D3.js | 7.8.5 | Visualisations avancÃ©es |
| | Pinia | 2.3.1 | State management |
| **Backend** | Go | 1.23 | API REST haute performance |
| | Gin | 1.9.1 | Framework HTTP |
| | GORM | 1.25.5 | ORM PostgreSQL |
| | Gorilla WebSocket | 1.5.1 | Streaming temps rÃ©el |
| | confluent-kafka-go | 2.3.0 | Consumer Kafka |
| **Data Pipeline** | Python | 3.11+ | Collecte et traitement |
| | Binance SDK | - | API WebSocket |
| | VADER Sentiment | - | Analyse de sentiment |
| **Infrastructure** | Apache Kafka | 7.4.0 | Message broker |
| | TimescaleDB | PG15 | Base time-series |
| | Redis | 7 | Cache |
| | MinIO | Latest | Object storage S3 |
| **Monitoring** | Prometheus | Latest | MÃ©triques |
| | Grafana | Latest | Dashboards |
| | Gatus | Latest | Health checks |

---

## PrÃ©requis

- **Docker** 20.10+
- **Docker Compose** 2.0+
- **RAM** : 8GB minimum (16GB recommandÃ©)
- **Disque** : 20GB minimum
- **Ports disponibles** : 3000, 8080, 7432, 9092, etc.

---

## Installation Rapide

```bash
# 1. Cloner le repository
git clone https://github.com/T-DAT-901/CryptoViz.git
cd CryptoViz

# 2. Configuration initiale
make setup
# Ã‰diter .env si nÃ©cessaire (clÃ©s API Binance optionnelles pour donnÃ©es publiques)

# 3. Compiler
make build

# 4. DÃ©marrer tous les services
make start

# 5. VÃ©rifier l'Ã©tat
make status
make health

# 6. AccÃ©der Ã  l'interface
# Frontend : http://localhost:3000
# API : http://localhost:8080
# Grafana : http://localhost:3001 (admin/admin)
```

### Commandes de DÃ©marrage Alternatives

```bash
make start-infra       # Infrastructure seule (DB, Kafka, Redis)
make start-services    # Microservices Python
make start-app         # Backend Go + Frontend Vue
make start-monitoring  # Stack Prometheus/Grafana
```

---

## Structure du Projet

```
CryptoViz/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ backend-go/           # API REST + WebSocket (Go 1.23)
â”‚   â”‚   â”œâ”€â”€ cmd/server/       # Point d'entrÃ©e
â”‚   â”‚   â”œâ”€â”€ internal/         # Code applicatif (Clean Architecture)
â”‚   â”‚   â”‚   â”œâ”€â”€ controllers/  # Handlers HTTP
â”‚   â”‚   â”‚   â”œâ”€â”€ kafka/        # Consumers Kafka
â”‚   â”‚   â”‚   â”œâ”€â”€ middleware/   # CORS, logging
â”‚   â”‚   â”‚   â””â”€â”€ websocket/    # Hub + Clients
â”‚   â”‚   â””â”€â”€ models/           # EntitÃ©s GORM
â”‚   â”‚
â”‚   â”œâ”€â”€ frontend-vue/         # Interface utilisateur (Vue.js 3)
â”‚   â”‚   â”œâ”€â”€ src/components/   # Composants rÃ©utilisables
â”‚   â”‚   â”œâ”€â”€ src/services/     # Clients API et WebSocket
â”‚   â”‚   â”œâ”€â”€ src/stores/       # State Pinia
â”‚   â”‚   â””â”€â”€ src/views/        # Pages
â”‚   â”‚
â”‚   â”œâ”€â”€ data-collector/       # Collecte Binance (Python)
â”‚   â”‚   â”œâ”€â”€ binance_client.py # WebSocket connection
â”‚   â”‚   â”œâ”€â”€ aggregator.py     # OHLCV aggregation
â”‚   â”‚   â””â”€â”€ historical_collector.py  # Backfill
â”‚   â”‚
â”‚   â”œâ”€â”€ news-scraper/         # ActualitÃ©s + Sentiment (Python)
â”‚   â”‚   â”œâ”€â”€ sources/          # Adaptateurs (RSS, Twitter, Reddit...)
â”‚   â”‚   â”œâ”€â”€ core/             # Kafka producer, sentiment analysis
â”‚   â”‚   â””â”€â”€ models/           # Article dataclass
â”‚   â”‚
â”‚   â””â”€â”€ indicators-scheduler/ # DÃ©clencheur indicateurs (Python)
â”‚       â””â”€â”€ scheduler.py      # Trigger des calculs SQL en DB
â”‚
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ init.sql              # SchÃ©ma initial + hypertables
â”‚   â”œâ”€â”€ setup-tiering.sql     # Fonctions hot/cold storage
â”‚   â”œâ”€â”€ setup-indicators.sql  # Continuous aggregates
â”‚   â””â”€â”€ 04-backfill-tracking.sql  # Gap detection
â”‚
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ prometheus/           # Configuration scraping
â”‚   â”œâ”€â”€ grafana/              # Dashboards prÃ©configurÃ©s
â”‚   â”‚   â””â”€â”€ dashboards/       # 5 dashboards JSON
â”‚   â””â”€â”€ gatus/                # Health checks
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ start.sh              # DÃ©marrage orchestrÃ©
â”‚   â”œâ”€â”€ stop.sh               # ArrÃªt propre
â”‚   â””â”€â”€ demo-tiering.sh       # DÃ©mo interactive tiering
â”‚
â”œâ”€â”€ docs/                     # Documentation technique
â”œâ”€â”€ docker-compose.yml        # Orchestration 17+ services
â”œâ”€â”€ docker-compose.mac.yml    # Override Mac/WSL2
â”œâ”€â”€ Makefile                  # 80+ commandes
â””â”€â”€ .env.example              # Template configuration
```

---

## Services et Ports

| Service | Port | Description |
|---------|------|-------------|
| **frontend-vue** | 3000 | Interface utilisateur Vue.js |
| **backend-go** | 8080 | API REST + WebSocket |
| **timescaledb** | 7432 | Base de donnÃ©es TimescaleDB |
| **kafka** | 9092 | Message broker |
| **kafka-ui** | 8082 | Interface de gestion Kafka |
| **redis** | 7379 | Cache |
| **minio** | 9000/9001 | API S3 / Console Web |
| **grafana** | 3001 | Dashboards monitoring |
| **prometheus** | 9090 | Collecte mÃ©triques |
| **gatus** | 8084 | Page de statut |

> **Note** : Les ports non-standards (7432 au lieu de 5432) Ã©vitent les conflits avec des installations locales.

---

## Pipeline de DonnÃ©es

```mermaid
sequenceDiagram
    participant B as Binance API
    participant DC as Data Collector
    participant K as Kafka
    participant BG as Backend Go
    participant TS as TimescaleDB
    participant WS as WebSocket
    participant FE as Frontend

    Note over B,FE: Flux d'ingestion temps rÃ©el

    B->>DC: WebSocket Stream (trades)
    DC->>K: Produce crypto.aggregated.*

    Note over K,FE: Flux de streaming + persistance

    K->>BG: Consume messages
    BG->>TS: INSERT candles
    BG->>WS: Broadcast to subscribers
    WS->>FE: Push temps rÃ©el

    Note over FE,TS: Flux de requÃªte historique

    FE->>BG: GET /api/v1/crypto/data
    BG->>TS: SELECT FROM all_candles
    TS->>BG: RÃ©sultats (hot + cold)
    BG->>FE: JSON response
```

### Topics Kafka

| Topic | RÃ©tention | Description |
|-------|-----------|-------------|
| `crypto.raw.trades` | 48h | Trades individuels |
| `crypto.aggregated.1m` | 30j | Candles 1 minute |
| `crypto.aggregated.5m` | 60j | Candles 5 minutes |
| `crypto.aggregated.15m` | 90j | Candles 15 minutes |
| `crypto.aggregated.1h` | 180j | Candles 1 heure |
| `crypto.aggregated.1d` | 2 ans | Candles journaliÃ¨res |
| `crypto.news` | 7j | Articles avec sentiment |

---

## Optimisations de Performance

Le backend Go implÃ©mente plusieurs optimisations critiques pour maximiser le throughput de consommation Kafka.

### Batch Commits Kafka

**ProblÃ¨me initial** : Un commit Kafka aprÃ¨s chaque message gÃ©nÃ¨re une latence de ~10-50ms par message, limitant le throughput Ã  ~600 messages/minute.

**Solution** : Commits groupÃ©s toutes les 5 secondes via un ticker.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AVANT (per-message)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Message 1 â†’ Process â†’ Commit (10ms)                        â”‚
â”‚  Message 2 â†’ Process â†’ Commit (10ms)                        â”‚
â”‚  Message 3 â†’ Process â†’ Commit (10ms)                        â”‚
â”‚  ...                                                         â”‚
â”‚  = 600 commits/minute = 600 round-trips broker              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    APRÃˆS (batch commit)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Message 1 â†’ Process â†’ (pending)                            â”‚
â”‚  Message 2 â†’ Process â†’ (pending)                            â”‚
â”‚  ...                                                         â”‚
â”‚  [5s ticker] â†’ Commit ALL â†’ (1 round-trip)                  â”‚
â”‚  = 12 commits/minute = 99% moins de round-trips             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Impact** : RÃ©duction de 99% des round-trips vers le broker Kafka.

### Batch Database Writes

Chaque handler bufferise les messages et les Ã©crit en batch selon deux critÃ¨res :

| Handler | Taille Batch | Intervalle Flush | DÃ©clencheur |
|---------|--------------|------------------|-------------|
| Trades | 500 | 100ms | Premier atteint |
| Candles | 100 | 250ms | Premier atteint |
| Indicators | 50 | 500ms | Premier atteint |
| News | 20 | 1s | Premier atteint |

**Avantages** :
- RÃ©duction des transactions DB de 90%+
- Utilisation optimale du pool de connexions
- Latence prÃ©visible (bounded par l'intervalle)

### Idempotence et SÃ©curitÃ©

Toutes les opÃ©rations restent **idempotentes** grÃ¢ce aux clauses `ON CONFLICT` :

```sql
-- Trades : ignore les duplicates
ON CONFLICT (trade_id, exchange, symbol, event_ts) DO NOTHING

-- Candles : merge intelligent des candles ouvertes
ON CONFLICT (window_start, exchange, symbol, timeframe) DO UPDATE SET
    high = GREATEST(candles.high, EXCLUDED.high),
    low = LEAST(candles.low, EXCLUDED.low),
    close = EXCLUDED.close,
    volume = candles.volume + EXCLUDED.volume
WHERE NOT candles.closed

-- Indicators : Ã©crase avec les valeurs recalculÃ©es
ON CONFLICT (time, symbol, timeframe, indicator_type) DO UPDATE SET
    value = EXCLUDED.value
```

**RÃ©sultat** : Aucune perte de donnÃ©es en cas de crash, redÃ©marrage ou retraitement.

### Impact Global

| MÃ©trique | Avant | AprÃ¨s | AmÃ©lioration |
|----------|-------|-------|--------------|
| Kafka round-trips/min | 6k+ | 12 | **-99%** |
| DB transactions/min | 6k+ | ~50 | **-92%** |
| Throughput potentiel | ~6k+/min | 100k+/min | **~20x** |
| Latence max (commit) | Variable | 5s | PrÃ©visible |

> **Note** : Le throughput rÃ©el dÃ©pend du volume de donnÃ©es entrantes depuis Binance, pas de la capacitÃ© du backend.

---

## Data Tiering (Hot/Cold Storage)

CryptoViz implÃ©mente un systÃ¨me de **tiering adaptatif** qui optimise les coÃ»ts de stockage tout en maintenant les performances.

```mermaid
flowchart LR
    subgraph Hot["ğŸ”¥ Hot Storage (SSD)"]
        direction TB
        H1[DonnÃ©es rÃ©centes]
        H2[RequÃªtes < 50ms]
        H3[Index optimisÃ©s]
    end

    subgraph Cold["â„ï¸ Cold Storage"]
        direction TB
        C1[DonnÃ©es historiques]
        C2[85% Ã©conomies]
        C3[Schema PostgreSQL]
    end

    subgraph Views["ğŸ‘ï¸ Vues UnifiÃ©es"]
        direction TB
        V1[all_candles]
        V2[all_indicators]
        V3[all_news]
    end

    Hot -->|"tier_old_*()"| Cold
    Hot --> Views
    Cold --> Views
    Views --> API[Backend API]

    style Hot fill:#ff6b6b,color:#fff
    style Cold fill:#4dabf7,color:#fff
    style Views fill:#51cf66,color:#fff
```

### RÃ©tention par Timeframe

| Timeframe | Hot Storage | Cold Storage | Total |
|-----------|-------------|--------------|-------|
| **1m** | 7 jours | 30 jours | 37 jours |
| **5m** | 14 jours | 90 jours | 104 jours |
| **15m** | 30 jours | 180 jours | 210 jours |
| **1h** | 90 jours | 730 jours | ~2 ans |
| **1d** | Permanent | - | âˆ |

### Commandes Tiering

```bash
# Voir les statistiques hot/cold
make tiering-stats

# DÃ©clencher le tiering manuellement
make tiering

# VÃ©rifier la configuration
make db-verify-tiering
```

### Architecture Technique

Le tiering utilise **dblink** pour des transactions autonomes, Ã©vitant les problÃ¨mes de mÃ©moire (OOM) lors du dÃ©placement de grandes quantitÃ©s de donnÃ©es :

```sql
-- Chaque batch de 5000 lignes est commitÃ© indÃ©pendamment
SELECT tier_old_candles();  -- DÃ©place les candles expirÃ©es
SELECT tier_old_indicators();  -- DÃ©place les indicateurs expirÃ©s
SELECT tier_old_news();  -- DÃ©place les news expirÃ©es
```

> **Documentation complÃ¨te** : [docs/COLDSTORAGE.md](docs/COLDSTORAGE.md)

---

## Indicateurs Techniques

| Indicateur | Description | ParamÃ¨tres | Formule |
|------------|-------------|------------|---------|
| **RSI** | Relative Strength Index | PÃ©riode: 14 | RSI = 100 - (100 / (1 + RS)) |
| **MACD** | Moving Average Convergence Divergence | 12, 26, 9 | MACD = EMA(12) - EMA(26) |
| **Bollinger Bands** | Bandes de volatilitÃ© | PÃ©riode: 20, Ã‰cart: 2Ïƒ | Upper/Lower = SMA Â± 2Ã—StdDev |
| **Momentum** | Indicateur de momentum | PÃ©riode: 10 | MOM = Close - Close[n] |

### Calcul et Stockage

Les indicateurs sont **calculÃ©s directement en SQL** dans TimescaleDB pour des performances optimales. L'**Indicators Scheduler** (Python) dÃ©clenche pÃ©riodiquement les fonctions SQL de calcul.

**Avantages du calcul cÃ´tÃ© DB** :
- Performance native sur les donnÃ©es time-series
- Pas de transfert de donnÃ©es entre services
- Utilisation des Continuous Aggregates TimescaleDB
- Pas de surcharge Kafka pour les indicateurs

```bash
# Voir les indicateurs calculÃ©s
make db-connect
SELECT * FROM indicators WHERE symbol = 'BTC/USDT' ORDER BY timestamp DESC LIMIT 10;
```

---

## Analyse de Sentiment

Le **News Scraper** intÃ¨gre une analyse de sentiment via VADER (Valence Aware Dictionary and sEntiment Reasoner).

### FonctionnalitÃ©s

- **Sources actuelles** : CoinDesk, CoinTelegraph (RSS)
- **Architecture extensible** : Stubs prÃªts pour Twitter, Reddit et autres sources
- **Score** : -1 (trÃ¨s nÃ©gatif) Ã  +1 (trÃ¨s positif)
- **DÃ©tection** : Identification automatique des cryptos mentionnÃ©es (BTC, ETH, etc.)
- **ScalabilitÃ© Kafka** : ConÃ§u pour gÃ©rer un grand volume de messages lors de l'ajout de nouvelles sources

### Exemple de RÃ©sultat

```json
{
  "title": "Bitcoin Surges Past $50,000",
  "sentiment_score": 0.85,
  "symbols": ["BTC", "BTCUSDT"],
  "source": "coindesk",
  "published_at": "2025-01-15T10:30:00Z"
}
```

---

## API REST

Base URL : `http://localhost:8080/api/v1`

| MÃ©thode | Endpoint | Description |
|---------|----------|-------------|
| GET | `/health` | Health check |
| GET | `/crypto/data?symbol=BTC/USDT&interval=1m` | DonnÃ©es historiques OHLCV |
| GET | `/crypto/latest?symbol=BTC/USDT` | Dernier prix |
| GET | `/stats?symbol=BTC/USDT` | Statistiques 24h |
| GET | `/indicators/:type?symbol=BTC/USDT` | Indicateur spÃ©cifique (rsi, macd, bollinger, momentum) |
| GET | `/indicators?symbol=BTC/USDT` | Tous les indicateurs |
| GET | `/news` | ActualitÃ©s rÃ©centes |
| GET | `/news/:symbol` | ActualitÃ©s par crypto |

### Exemple de RequÃªte

```bash
# RÃ©cupÃ©rer les candles 5m de BTC/USDT
curl "http://localhost:8080/api/v1/crypto/data?symbol=BTC/USDT&interval=5m&limit=100"

# RÃ©cupÃ©rer le RSI
curl "http://localhost:8080/api/v1/indicators/rsi?symbol=BTC/USDT"
```

> **Documentation complÃ¨te** : [docs/api.md](docs/api.md)

---

## WebSocket Streaming

Endpoint : `ws://localhost:8080/ws/crypto`

### Messages SupportÃ©s

```json
// Souscrire aux trades BTC
{"action": "subscribe", "type": "trade", "symbol": "BTC/USDT"}

// Souscrire Ã  toutes les candles 5m
{"action": "subscribe", "type": "candle", "symbol": "*", "timeframe": "5m"}

// Se dÃ©sabonner
{"action": "unsubscribe", "type": "trade", "symbol": "BTC/USDT"}

// Lister les souscriptions
{"action": "list_subscriptions"}
```

### Formats de RÃ©ponse

```json
// Trade
{
  "type": "trade",
  "data": {
    "symbol": "BTC/USDT",
    "price": 42150.50,
    "quantity": 0.5,
    "timestamp": "2025-01-15T10:30:00Z"
  }
}

// Candle
{
  "type": "candle",
  "data": {
    "symbol": "BTC/USDT",
    "timeframe": "5m",
    "open": 42100,
    "high": 42200,
    "low": 42050,
    "close": 42150,
    "volume": 125.5
  }
}
```

---

## Commandes Makefile

### Gestion des Services

```bash
make start              # DÃ©marrer tous les services
make stop               # ArrÃªter proprement
make stop-force         # ArrÃªt forcÃ©
make restart            # RedÃ©marrer tout
make restart-service SERVICE=backend-go  # RedÃ©marrer un service
make status             # Ã‰tat des conteneurs
make health             # VÃ©rifier la santÃ©
make logs               # Logs en temps rÃ©el
make logs-service SERVICE=data-collector  # Logs d'un service
```

### Base de DonnÃ©es

```bash
make db-connect         # Shell psql
make db-backup          # Sauvegarde
make db-restore BACKUP=file.sql  # Restauration
make db-reset           # Reset complet (âš ï¸ perte de donnÃ©es)
make tiering            # Lancer le tiering hotâ†’cold
make tiering-stats      # Distribution hot/cold
```

### Kafka

```bash
make kafka-topics       # Lister les topics
make kafka-console-consumer TOPIC=crypto.raw.trades  # Ã‰couter un topic
make kafka-create-topic TOPIC=nouveau.topic  # CrÃ©er un topic
```

### DÃ©veloppement

```bash
make dev-backend        # Backend Go en mode dev
make dev-frontend       # Frontend Vue en mode dev
make build              # Construire toutes les images
make build-service SERVICE=backend-go  # Construire un service
make test               # ExÃ©cuter les tests
make lint               # VÃ©rifier le code
make format             # Formater le code
```

### Monitoring

```bash
make monitor            # Afficher toutes les URLs
make grafana-console    # Info connexion Grafana
make prometheus-ui      # Info Prometheus
make minio-console      # Info MinIO
```

---

## Monitoring

### Stack ComplÃ¨te

| Outil | URL | Credentials | Description |
|-------|-----|-------------|-------------|
| **Grafana** | http://localhost:3001 | admin / admin | Dashboards |
| **Prometheus** | http://localhost:9090 | - | MÃ©triques |
| **Kafka UI** | http://localhost:8082 | - | Topics Kafka |
| **Gatus** | http://localhost:8084 | - | Health checks |
| **MinIO** | http://localhost:9001 | minioadmin / minioadmin | Object storage |

### Dashboards Grafana PrÃ©configurÃ©s

1. **CryptoViz Overview** - MÃ©triques applicatives
2. **PostgreSQL Database** - MÃ©triques TimescaleDB
3. **Kafka Exporter** - Lag consumers, throughput
4. **Node Exporter** - MÃ©triques systÃ¨me
5. **cAdvisor** - MÃ©triques conteneurs

### Exporters DÃ©ployÃ©s

- **Node Exporter** (9100) - CPU, RAM, Disk
- **PostgreSQL Exporter** (9187) - Connexions, requÃªtes, locks
- **Redis Exporter** (9121) - Hits/misses, mÃ©moire
- **Kafka Exporter** (9308) - Lag, messages/sec
- **cAdvisor** (8083) - Conteneurs Docker

---

## Configuration

### Variables d'Environnement Principales

Copier `.env.example` vers `.env` et adapter :

```bash
# API Binance (optionnel pour donnÃ©es publiques)
BINANCE_API_KEY=
BINANCE_SECRET_KEY=

# Base de donnÃ©es
TIMESCALE_HOST=timescaledb
TIMESCALE_PORT=5432
TIMESCALE_DB=cryptoviz
TIMESCALE_USER=postgres
TIMESCALE_PASSWORD=password

# Kafka
KAFKA_BROKERS=kafka:29092

# Data Collector
QUOTE_CURRENCIES=USDT,BUSD,FDUSD
MIN_VOLUME=5000000
MAX_SYMBOLS=20
ENABLE_BACKFILL=true
BACKFILL_LOOKBACK_DAYS=365
BACKFILL_TIMEFRAMES=1m,5m,15m,1h,1d

# Frontend (build-time)
VITE_API_URL=http://localhost:8080
VITE_WS_URL=ws://localhost:8080/ws/crypto
VITE_USE_MOCK=false
```

### Configuration AvancÃ©e

- **RÃ©tention tiering** : Configurable par timeframe dans `.env`
- **MÃ©moire TimescaleDB** : Ajustable dans `docker-compose.yml` (6GB par dÃ©faut)
- **Partitions Kafka** : 3 par topic par dÃ©faut

---

## Documentation

| Document | Description |
|----------|-------------|
| [DEV.md](DEV.md) | Guide dÃ©veloppeur, workflows, troubleshooting |
| [docs/api.md](docs/api.md) | Documentation API REST complÃ¨te |
| [docs/COLDSTORAGE.md](docs/COLDSTORAGE.md) | Architecture Data Tiering |
| [docs/ARCHITECTURE.md](docs/ARCHITECTURE.md) | Architecture Backend Go |
| [docs/ports-configuration.md](docs/ports-configuration.md) | Configuration des ports |

---

## Ã‰volutions Potentielles

Cette section prÃ©sente les axes d'amÃ©lioration pour scaler CryptoViz vers des charges de production plus importantes.

### ğŸ”§ Scaling Horizontal (Backend)

**ProblÃ¨me actuel** : Un seul backend-go consomme tous les partitions Kafka sÃ©quentiellement.

**Solution** : DÃ©ployer plusieurs instances backend-go avec plus de partitions Kafka.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ACTUEL (1 instance)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  backend-go â† P0, P1, P2 (sÃ©quentiel)                       â”‚
â”‚  CapacitÃ©: ~55K msg/min                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    SCALÃ‰ (3 instances)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  backend-go-1 â† P0, P1                                       â”‚
â”‚  backend-go-2 â† P2, P3                                       â”‚
â”‚  backend-go-3 â† P4, P5                                       â”‚
â”‚  CapacitÃ©: ~150K+ msg/min                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Modifications requises** :
- `docker-compose.yml` : Augmenter `KAFKA_NUM_PARTITIONS` (6, 9, 12...)
- DÃ©ployer plusieurs rÃ©plicas backend-go (mÃªme consumer group)
- Tous les rÃ©plicas partagent la mÃªme DB et le mÃªme consumer group

### ğŸ“ˆ Upgrade API Binance

| Tier | Rate Limit | Symboles | CoÃ»t |
|------|------------|----------|------|
| **Free** | 6,000 weight/min | IllimitÃ©* | Gratuit |
| **VIP 1** | 12,000 weight/min | IllimitÃ© | Volume-based |
| **VIP 2+** | 18,000+ weight/min | IllimitÃ© | Volume-based |

*Le nombre de symboles n'est pas limitÃ©, mais le rate limit contraint le dÃ©bit de backfill.

### ğŸ—„ï¸ Optimisation Base de DonnÃ©es

| AmÃ©lioration | Impact | Effort |
|--------------|--------|--------|
| **TimescaleDB dÃ©diÃ©** | Isolation CPU/RAM | Faible |
| **SSD NVMe** | Latence write -50% | Infrastructure |
| **RÃ©plication read** | Queries parallÃ¨les | Moyen |
| **Sharding par symbole** | Scale horizontal | Ã‰levÃ© |

### â˜¸ï¸ DÃ©ploiement Kubernetes

L'architecture est **cloud-ready** pour Kubernetes :

```yaml
# Exemple HPA pour auto-scaling
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
spec:
  scaleTargetRef:
    name: backend-go
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      targetAverageUtilization: 70
```

**Services Ã  dÃ©ployer** :
- Backend-go (StatelessSet, HPA)
- TimescaleDB (StatefulSet ou managed service)
- Kafka (Strimzi operator ou Confluent Cloud)
- Redis (StatefulSet ou ElastiCache)

### ğŸŒ Multi-Exchange

Extension vers d'autres exchanges (architecture prÃªte) :

| Exchange | API Type | Effort |
|----------|----------|--------|
| Coinbase | REST + WS | 2-3 jours |
| Kraken | REST + WS | 2-3 jours |
| FTX | REST + WS | 2-3 jours |
| Bybit | REST + WS | 2-3 jours |

**Modifications** : Nouveau collector par exchange, mÃªme pipeline Kafka/DB.

### ğŸ“° Sources de News Additionnelles

Le news-scraper actuel utilise uniquement les flux RSS :

| Source Actuelle | Type | Limitations |
|-----------------|------|-------------|
| CoinDesk | RSS | ~10 articles/jour |
| CoinTelegraph | RSS | ~15 articles/jour |

**AmÃ©liorations possibles** :

| Source | Type | Effort | Impact |
|--------|------|--------|--------|
| **Twitter/X API** | API REST | Moyen | Haute frÃ©quence, sentiment temps rÃ©el |
| **Reddit API** | API REST | Faible | r/cryptocurrency, r/bitcoin |
| **CryptoCompare** | API REST | Faible | News agrÃ©gÃ©es multi-sources |
| **Messari** | API REST | Moyen | Analyse professionnelle |
| **The Block** | RSS/Scraping | Faible | ActualitÃ©s institutionnelles |

> L'architecture Kafka est **dÃ©jÃ  dimensionnÃ©e** pour absorber un volume plus important de news.

### ğŸ“Š AmÃ©liorations Frontend

#### Pagination des Graphiques ChartJS

**Limitation actuelle** : Les graphiques chargent toutes les donnÃ©es en mÃ©moire, ce qui peut ralentir avec des historiques longs (10+ ans).

**Solution** : Pagination cÃ´tÃ© serveur + lazy loading :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ACTUEL (chargement complet)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  GET /candles?symbol=BTC&limit=ALL                          â”‚
â”‚  â†’ Charge 3M+ points en mÃ©moire                             â”‚
â”‚  â†’ Freeze UI pendant chargement                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    PROPOSÃ‰ (pagination)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  GET /candles?symbol=BTC&from=2025-01-01&to=2025-01-31     â”‚
â”‚  â†’ Charge uniquement la fenÃªtre visible                     â”‚
â”‚  â†’ Scroll/zoom dÃ©clenche nouvelles requÃªtes                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Autres AmÃ©liorations UI

| Feature | Description | ComplexitÃ© |
|---------|-------------|------------|
| **Zoom sÃ©mantique** | AgrÃ©gation auto (1mâ†’5mâ†’1h) selon zoom | Moyenne |
| **Comparaison multi-symboles** | Overlay plusieurs cryptos | Moyenne |
| **Raccourcis clavier** | Navigation rapide | Faible |
| **Export PNG/CSV** | Export graphiques et donnÃ©es | Faible |
| **Watchlists** | Favoris personnalisÃ©s | Moyenne |

### ğŸ” SÃ©curitÃ© et Authentification

| Feature | Description | ComplexitÃ© |
|---------|-------------|------------|
| **Authentification JWT** | Login/register avec tokens sÃ©curisÃ©s | Moyenne |
| **OAuth2** | Login via Google, GitHub | Moyenne |
| **Rate limiting API** | Protection contre abus (429 Too Many Requests) | Faible |
| **RBAC** | RÃ´les utilisateur (admin, viewer) | Moyenne |

### ğŸ¤– FonctionnalitÃ©s AvancÃ©es

| Feature | Description | ComplexitÃ© |
|---------|-------------|------------|
| **Alertes prix** | Notifications seuil (email, push, Telegram) | Moyenne |
| **Backtesting** | Simulation stratÃ©gies sur historique | Ã‰levÃ©e |
| **ML Predictions** | PrÃ©diction prix/volatilitÃ© | TrÃ¨s Ã©levÃ©e |
| **Portfolio tracking** | Suivi positions multi-exchange | Moyenne |
| **Heatmaps** | CorrÃ©lation inter-cryptos | Moyenne |

### ğŸ” AmÃ©liorations Backend

| AmÃ©lioration | Description | Effort |
|--------------|-------------|--------|
| **API GraphQL** | RequÃªtes flexibles, moins de sur-fetch | Moyen |
| **Cache API Redis** | Mise en cache des rÃ©ponses API frÃ©quentes | Faible |
| **SÃ©paration API/Worker** | DÃ©couplage lecture/Ã©criture | Moyen |

---

## Ã‰quipe et Licence

### Projet Epitech T-DAT-901

CryptoViz a Ã©tÃ© dÃ©veloppÃ© dans le cadre du projet **T-DAT-901** Ã  Epitech.

### Licence

MIT License - voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

---

<p align="center">
  <b>CryptoViz</b> - Terminal de Trading Crypto en Temps RÃ©el<br/>
  <sub>Epitech T-DAT-901 | 2025</sub>
</p>
